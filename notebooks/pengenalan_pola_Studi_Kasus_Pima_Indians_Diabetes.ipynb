{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YVfSksXrJYts",
        "mdNqepxBJdCS",
        "MxGJtedgKKYP",
        "WSHXyPeMLcnQ",
        "l9tbblNJLvKX",
        "xVsqeh6yMFgU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinggarM/Pima-Indians-Diabetes-Classification-using-Various-Supervised-Algorithms/blob/main/pengenalan_pola_Studi_Kasus_Pima_Indians_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "3dQQnbaRQyuu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9c0bd083zcr",
        "outputId": "974a3ac3-cf1c-4e66-a11d-ad96882904ee"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnAf0mZQ6Pj4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_diabetes = pd.read_csv('/content/gdrive/MyDrive/Upload/Akademik/Pengenalan Pola/diabetes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "pDhmvM4uQ1_a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bpSTDDL5AsTJ",
        "outputId": "61d3a0bf-cf6b-4676-b02f-432099b87fea"
      },
      "source": [
        "df_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxEzLBf0AnPa",
        "outputId": "d713afbe-e2c2-4d1e-803a-48b18f109088"
      },
      "source": [
        "df_diabetes.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "mTbu2GHyAvLq",
        "outputId": "c3e7024c-64dc-4dc2-bd98-8286d3c263e0"
      },
      "source": [
        "df_diabetes.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  ...         Age     Outcome\n",
              "count   768.000000  768.000000  ...  768.000000  768.000000\n",
              "mean      3.845052  120.894531  ...   33.240885    0.348958\n",
              "std       3.369578   31.972618  ...   11.760232    0.476951\n",
              "min       0.000000    0.000000  ...   21.000000    0.000000\n",
              "25%       1.000000   99.000000  ...   24.000000    0.000000\n",
              "50%       3.000000  117.000000  ...   29.000000    0.000000\n",
              "75%       6.000000  140.250000  ...   41.000000    1.000000\n",
              "max      17.000000  199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "yJqqaeQDQ95n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsARVsknBslP"
      },
      "source": [
        "# memisahkan atribut fitur (selain target/ kelas prediksi)\n",
        "x = df_diabetes[df_diabetes.columns[:8]]\n",
        "\n",
        "# memisahkan target/ kelas prediksi (0 dan 1)\n",
        "y = df_diabetes['Outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d02SAixMA_aQ"
      },
      "source": [
        "# melakukan standarisasi nilai fitur\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x_transformed = scaler.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQxUsJOOR79e"
      },
      "source": [
        "x_df_transformed = pd.DataFrame(scaler.transform(x),columns = x.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "BGTeT4dzSH4k",
        "outputId": "edbbbc3d-da9f-42e7-96b1-7961ccd6a9b4"
      },
      "source": [
        "x_df_transformed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>0.848324</td>\n",
              "      <td>0.149641</td>\n",
              "      <td>0.907270</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.204013</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>1.425995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-1.123396</td>\n",
              "      <td>-0.160546</td>\n",
              "      <td>0.530902</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.684422</td>\n",
              "      <td>-0.365061</td>\n",
              "      <td>-0.190672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.233880</td>\n",
              "      <td>1.943724</td>\n",
              "      <td>-0.263941</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.103255</td>\n",
              "      <td>0.604397</td>\n",
              "      <td>-0.105584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-0.998208</td>\n",
              "      <td>-0.160546</td>\n",
              "      <td>0.154533</td>\n",
              "      <td>0.123302</td>\n",
              "      <td>-0.494043</td>\n",
              "      <td>-0.920763</td>\n",
              "      <td>-1.041549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>0.504055</td>\n",
              "      <td>-1.504687</td>\n",
              "      <td>0.907270</td>\n",
              "      <td>0.765836</td>\n",
              "      <td>1.409746</td>\n",
              "      <td>5.484909</td>\n",
              "      <td>-0.020496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>1.827813</td>\n",
              "      <td>-0.622642</td>\n",
              "      <td>0.356432</td>\n",
              "      <td>1.722735</td>\n",
              "      <td>0.870031</td>\n",
              "      <td>0.115169</td>\n",
              "      <td>-0.908682</td>\n",
              "      <td>2.532136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>-0.547919</td>\n",
              "      <td>0.034598</td>\n",
              "      <td>0.046245</td>\n",
              "      <td>0.405445</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.610154</td>\n",
              "      <td>-0.398282</td>\n",
              "      <td>-0.531023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>0.149641</td>\n",
              "      <td>0.154533</td>\n",
              "      <td>0.279594</td>\n",
              "      <td>-0.735190</td>\n",
              "      <td>-0.685193</td>\n",
              "      <td>-0.275760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>0.159787</td>\n",
              "      <td>-0.470732</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.240205</td>\n",
              "      <td>-0.371101</td>\n",
              "      <td>1.170732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-0.873019</td>\n",
              "      <td>0.046245</td>\n",
              "      <td>0.656358</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.202129</td>\n",
              "      <td>-0.473785</td>\n",
              "      <td>-0.871374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies   Glucose  ...  DiabetesPedigreeFunction       Age\n",
              "0       0.639947  0.848324  ...                  0.468492  1.425995\n",
              "1      -0.844885 -1.123396  ...                 -0.365061 -0.190672\n",
              "2       1.233880  1.943724  ...                  0.604397 -0.105584\n",
              "3      -0.844885 -0.998208  ...                 -0.920763 -1.041549\n",
              "4      -1.141852  0.504055  ...                  5.484909 -0.020496\n",
              "..           ...       ...  ...                       ...       ...\n",
              "763     1.827813 -0.622642  ...                 -0.908682  2.532136\n",
              "764    -0.547919  0.034598  ...                 -0.398282 -0.531023\n",
              "765     0.342981  0.003301  ...                 -0.685193 -0.275760\n",
              "766    -0.844885  0.159787  ...                 -0.371101  1.170732\n",
              "767    -0.844885 -0.873019  ...                 -0.473785 -0.871374\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "Hp5HC-1BQ_dj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe6NvS5yCetH"
      },
      "source": [
        "# memisahkan data untuk training dan testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_transformed, y, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Preparation"
      ],
      "metadata": {
        "id": "ZeZhX4uORBAT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHXr4KWwBfax"
      },
      "source": [
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wgJmHieCVzw"
      },
      "source": [
        "parameters = {'bootstrap': True,\n",
        "              'min_samples_leaf': 3,\n",
        "              'n_estimators': 50,\n",
        "              'min_samples_split': 10,\n",
        "              'max_features': 'sqrt',\n",
        "              'max_depth': 6,\n",
        "              'max_leaf_nodes': None}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVfSksXrJYts"
      },
      "source": [
        "## **Using Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQRKmvzGI_mk"
      },
      "source": [
        "RF_model = RandomForestClassifier(**parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9EiVq25JLBr",
        "outputId": "b2c1f972-8625-418e-e098-e2a0e75b68c6"
      },
      "source": [
        "RF_model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=6, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=3, min_samples_split=10,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSVkxcz5JPxD"
      },
      "source": [
        "RF_predictions = RF_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-MDOvtNJTdq",
        "outputId": "50c29aeb-d184-4b40-8583-3f1640ecbdc2"
      },
      "source": [
        "score = accuracy_score(y_test ,RF_predictions)\n",
        "print('Accuracy Random Forest Model:',score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Random Forest Model: 0.78125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdNqepxBJdCS"
      },
      "source": [
        "## **Using Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0qTQNL7Je_M"
      },
      "source": [
        "# Build a neural network :\n",
        "NN_model = Sequential()\n",
        "\n",
        "NN_model.add(Dense(256, input_dim = x_transformed.shape[1], activation='relu'))\n",
        "NN_model.add(Dense(256, activation='relu'))\n",
        "NN_model.add(Dense(256, activation='relu'))\n",
        "NN_model.add(Dense(256, activation='relu'))\n",
        "NN_model.add(Dense(1, activation='sigmoid'))\n",
        "NN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNxKZucQJjJy"
      },
      "source": [
        "checkpoint_name = 'BestWeights.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_accuracy', verbose = 1, save_best_only = True, mode ='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BM-T1nkJyRV",
        "outputId": "79d0f239-bbe9-4c3b-ceae-8ee53bc53176"
      },
      "source": [
        "t0_nn = time()\n",
        "NN_model.fit(x_train, y_train, epochs=150, batch_size=64, validation_split = 0.2, callbacks=callbacks_list)\n",
        "train_test_time = time() - t0_nn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "8/8 [==============================] - 1s 34ms/step - loss: 0.6538 - accuracy: 0.5725 - val_loss: 0.4887 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79310, saving model to BestWeights.hdf5\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5034 - accuracy: 0.7602 - val_loss: 0.5040 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.79310 to 0.82759, saving model to BestWeights.hdf5\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4609 - accuracy: 0.7739 - val_loss: 0.5008 - val_accuracy: 0.8017\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.82759\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4272 - accuracy: 0.7936 - val_loss: 0.5135 - val_accuracy: 0.8190\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.82759\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4255 - accuracy: 0.7912 - val_loss: 0.5354 - val_accuracy: 0.7845\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.82759\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3790 - accuracy: 0.8098 - val_loss: 0.5223 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.82759\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3979 - accuracy: 0.8256 - val_loss: 0.6206 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.82759\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.7848 - val_loss: 0.5305 - val_accuracy: 0.7845\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.82759\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3546 - accuracy: 0.8448 - val_loss: 0.6209 - val_accuracy: 0.7759\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.82759\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3533 - accuracy: 0.8250 - val_loss: 0.5883 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.82759\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.8318 - val_loss: 0.6570 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.82759\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3344 - accuracy: 0.8524 - val_loss: 0.6780 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.82759\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2801 - accuracy: 0.8717 - val_loss: 0.7396 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.82759\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.8627 - val_loss: 0.6948 - val_accuracy: 0.7845\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.82759\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2984 - accuracy: 0.8550 - val_loss: 0.7815 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.82759\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2838 - accuracy: 0.8649 - val_loss: 0.8497 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.82759\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2469 - accuracy: 0.8880 - val_loss: 0.7946 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.82759\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2456 - accuracy: 0.8884 - val_loss: 0.8863 - val_accuracy: 0.7414\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.82759\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2034 - accuracy: 0.9095 - val_loss: 0.9655 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.82759\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1902 - accuracy: 0.9087 - val_loss: 1.1051 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.82759\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9167 - val_loss: 1.1601 - val_accuracy: 0.7328\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.82759\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1658 - accuracy: 0.9301 - val_loss: 1.1409 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.82759\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9300 - val_loss: 1.2278 - val_accuracy: 0.7155\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.82759\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 0.9377 - val_loss: 1.3513 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.82759\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1551 - accuracy: 0.9246 - val_loss: 1.3822 - val_accuracy: 0.6810\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.82759\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1210 - accuracy: 0.9607 - val_loss: 1.2253 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.82759\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.9371 - val_loss: 1.3939 - val_accuracy: 0.6983\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.82759\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 1.6218 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.82759\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0871 - accuracy: 0.9701 - val_loss: 1.5658 - val_accuracy: 0.7241\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.82759\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9799 - val_loss: 1.6902 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.82759\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0670 - accuracy: 0.9834 - val_loss: 1.7785 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.82759\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0645 - accuracy: 0.9747 - val_loss: 1.9690 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.82759\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0642 - accuracy: 0.9740 - val_loss: 2.1355 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.82759\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9893 - val_loss: 1.9283 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.82759\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9829 - val_loss: 2.1278 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.82759\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1161 - accuracy: 0.9673 - val_loss: 2.1932 - val_accuracy: 0.6293\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.82759\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1530 - accuracy: 0.9320 - val_loss: 2.4902 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.82759\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2432 - accuracy: 0.9163 - val_loss: 1.7326 - val_accuracy: 0.7155\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.82759\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1062 - accuracy: 0.9471 - val_loss: 1.6295 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.82759\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0734 - accuracy: 0.9845 - val_loss: 1.7959 - val_accuracy: 0.6983\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.82759\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 1.8434 - val_accuracy: 0.6983\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.82759\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0394 - accuracy: 0.9936 - val_loss: 2.1544 - val_accuracy: 0.6810\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.82759\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9943 - val_loss: 2.1052 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.82759\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9990 - val_loss: 2.4715 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.82759\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9986 - val_loss: 2.3885 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.82759\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 2.5743 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.82759\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9993 - val_loss: 2.5742 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.82759\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 2.6865 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.82759\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.7143 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.82759\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.6611 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.82759\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.8717 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.82759\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.8725 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.82759\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8979 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.82759\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9637 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.82759\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0263 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.82759\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0680 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.82759\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1120 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.82759\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1684 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.82759\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 0.9976 - val_loss: 3.1673 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.82759\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2123 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.82759\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2575 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.82759\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2767 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.82759\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2881 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.82759\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3220 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.82759\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3554 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.82759\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3901 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.82759\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4180 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.82759\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.6446e-04 - accuracy: 1.0000 - val_loss: 3.4383 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.82759\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.4620e-04 - accuracy: 1.0000 - val_loss: 3.4495 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.82759\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.8317e-04 - accuracy: 1.0000 - val_loss: 3.4737 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.82759\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.1554e-04 - accuracy: 1.0000 - val_loss: 3.4970 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.82759\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.3638e-04 - accuracy: 1.0000 - val_loss: 3.5197 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.82759\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.2459e-04 - accuracy: 1.0000 - val_loss: 3.5419 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.82759\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.5461e-04 - accuracy: 1.0000 - val_loss: 3.5636 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.82759\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.2394e-04 - accuracy: 1.0000 - val_loss: 3.5866 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.82759\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.8471e-04 - accuracy: 1.0000 - val_loss: 3.6064 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.82759\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.4450e-04 - accuracy: 1.0000 - val_loss: 3.6168 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.82759\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.0856e-04 - accuracy: 1.0000 - val_loss: 3.6366 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.82759\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.2769e-04 - accuracy: 1.0000 - val_loss: 3.6489 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.82759\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.3407e-04 - accuracy: 1.0000 - val_loss: 3.6654 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.82759\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 5.5427e-04 - accuracy: 1.0000 - val_loss: 3.6920 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.82759\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.6898e-04 - accuracy: 1.0000 - val_loss: 3.7046 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.82759\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.4140e-04 - accuracy: 1.0000 - val_loss: 3.7203 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.82759\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.4382e-04 - accuracy: 1.0000 - val_loss: 3.7310 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.82759\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.5166e-04 - accuracy: 1.0000 - val_loss: 3.7380 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.82759\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.7395e-04 - accuracy: 1.0000 - val_loss: 3.7609 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.82759\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.6453e-04 - accuracy: 1.0000 - val_loss: 3.7783 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.82759\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0891e-04 - accuracy: 1.0000 - val_loss: 3.7977 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.82759\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.3217e-04 - accuracy: 1.0000 - val_loss: 3.8154 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.82759\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.7674e-04 - accuracy: 1.0000 - val_loss: 3.8308 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.82759\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.6105e-04 - accuracy: 1.0000 - val_loss: 3.8441 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.82759\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.7945e-04 - accuracy: 1.0000 - val_loss: 3.8535 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.82759\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.5692e-04 - accuracy: 1.0000 - val_loss: 3.8647 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.82759\n",
            "Epoch 94/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.2334e-04 - accuracy: 1.0000 - val_loss: 3.8772 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.82759\n",
            "Epoch 95/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.3210e-04 - accuracy: 1.0000 - val_loss: 3.8950 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.82759\n",
            "Epoch 96/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.8694e-04 - accuracy: 1.0000 - val_loss: 3.9038 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.82759\n",
            "Epoch 97/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.1096e-04 - accuracy: 1.0000 - val_loss: 3.9131 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.82759\n",
            "Epoch 98/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.0676e-04 - accuracy: 1.0000 - val_loss: 3.9264 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.82759\n",
            "Epoch 99/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.0223e-04 - accuracy: 1.0000 - val_loss: 3.9407 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.82759\n",
            "Epoch 100/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.6289e-04 - accuracy: 1.0000 - val_loss: 3.9546 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.82759\n",
            "Epoch 101/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.2162e-04 - accuracy: 1.0000 - val_loss: 3.9697 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.82759\n",
            "Epoch 102/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.6028e-04 - accuracy: 1.0000 - val_loss: 3.9813 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.82759\n",
            "Epoch 103/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.8411e-04 - accuracy: 1.0000 - val_loss: 3.9919 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.82759\n",
            "Epoch 104/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.3151e-04 - accuracy: 1.0000 - val_loss: 4.0017 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.82759\n",
            "Epoch 105/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.7584e-04 - accuracy: 1.0000 - val_loss: 4.0177 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.82759\n",
            "Epoch 106/150\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 2.3690e-04 - accuracy: 1.0000 - val_loss: 4.0284 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.82759\n",
            "Epoch 107/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.4095e-04 - accuracy: 1.0000 - val_loss: 4.0364 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.82759\n",
            "Epoch 108/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.2794e-04 - accuracy: 1.0000 - val_loss: 4.0463 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.82759\n",
            "Epoch 109/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.3808e-04 - accuracy: 1.0000 - val_loss: 4.0586 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.82759\n",
            "Epoch 110/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.2374e-04 - accuracy: 1.0000 - val_loss: 4.0746 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.82759\n",
            "Epoch 111/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.1301e-04 - accuracy: 1.0000 - val_loss: 4.0867 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.82759\n",
            "Epoch 112/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.2952e-04 - accuracy: 1.0000 - val_loss: 4.0943 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.82759\n",
            "Epoch 113/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.3879e-04 - accuracy: 1.0000 - val_loss: 4.1032 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.82759\n",
            "Epoch 114/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.8834e-04 - accuracy: 1.0000 - val_loss: 4.1120 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.82759\n",
            "Epoch 115/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7931e-04 - accuracy: 1.0000 - val_loss: 4.1220 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.82759\n",
            "Epoch 116/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.7995e-04 - accuracy: 1.0000 - val_loss: 4.1300 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.82759\n",
            "Epoch 117/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.9624e-04 - accuracy: 1.0000 - val_loss: 4.1419 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.82759\n",
            "Epoch 118/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6133e-04 - accuracy: 1.0000 - val_loss: 4.1551 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.82759\n",
            "Epoch 119/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4608e-04 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.82759\n",
            "Epoch 120/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5525e-04 - accuracy: 1.0000 - val_loss: 4.1782 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.82759\n",
            "Epoch 121/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4911e-04 - accuracy: 1.0000 - val_loss: 4.1864 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.82759\n",
            "Epoch 122/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4029e-04 - accuracy: 1.0000 - val_loss: 4.1964 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.82759\n",
            "Epoch 123/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5633e-04 - accuracy: 1.0000 - val_loss: 4.2053 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.82759\n",
            "Epoch 124/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4268e-04 - accuracy: 1.0000 - val_loss: 4.2143 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.82759\n",
            "Epoch 125/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4126e-04 - accuracy: 1.0000 - val_loss: 4.2240 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.82759\n",
            "Epoch 126/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.4282e-04 - accuracy: 1.0000 - val_loss: 4.2363 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.82759\n",
            "Epoch 127/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3725e-04 - accuracy: 1.0000 - val_loss: 4.2463 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.82759\n",
            "Epoch 128/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.4240e-04 - accuracy: 1.0000 - val_loss: 4.2557 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.82759\n",
            "Epoch 129/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.3353e-04 - accuracy: 1.0000 - val_loss: 4.2664 - val_accuracy: 0.6379\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.82759\n",
            "Epoch 130/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2591e-04 - accuracy: 1.0000 - val_loss: 4.2747 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.82759\n",
            "Epoch 131/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1702e-04 - accuracy: 1.0000 - val_loss: 4.2826 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.82759\n",
            "Epoch 132/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1722e-04 - accuracy: 1.0000 - val_loss: 4.2902 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.82759\n",
            "Epoch 133/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1884e-04 - accuracy: 1.0000 - val_loss: 4.2981 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.82759\n",
            "Epoch 134/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1543e-04 - accuracy: 1.0000 - val_loss: 4.3086 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.82759\n",
            "Epoch 135/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0366e-04 - accuracy: 1.0000 - val_loss: 4.3166 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.82759\n",
            "Epoch 136/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 4.3245 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.82759\n",
            "Epoch 137/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0646e-04 - accuracy: 1.0000 - val_loss: 4.3340 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.82759\n",
            "Epoch 138/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2376e-04 - accuracy: 1.0000 - val_loss: 4.3444 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.82759\n",
            "Epoch 139/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0050e-04 - accuracy: 1.0000 - val_loss: 4.3540 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.82759\n",
            "Epoch 140/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.7218e-05 - accuracy: 1.0000 - val_loss: 4.3639 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.82759\n",
            "Epoch 141/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1055e-04 - accuracy: 1.0000 - val_loss: 4.3754 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.82759\n",
            "Epoch 142/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.9565e-05 - accuracy: 1.0000 - val_loss: 4.3830 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.82759\n",
            "Epoch 143/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0009e-04 - accuracy: 1.0000 - val_loss: 4.3911 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.82759\n",
            "Epoch 144/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0093e-04 - accuracy: 1.0000 - val_loss: 4.3986 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 0.82759\n",
            "Epoch 145/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.9131e-05 - accuracy: 1.0000 - val_loss: 4.4072 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 0.82759\n",
            "Epoch 146/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.3485e-05 - accuracy: 1.0000 - val_loss: 4.4153 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 0.82759\n",
            "Epoch 147/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 9.3946e-05 - accuracy: 1.0000 - val_loss: 4.4237 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 0.82759\n",
            "Epoch 148/150\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.4425e-05 - accuracy: 1.0000 - val_loss: 4.4317 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 0.82759\n",
            "Epoch 149/150\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.2138e-05 - accuracy: 1.0000 - val_loss: 4.4384 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 0.82759\n",
            "Epoch 150/150\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.9174e-05 - accuracy: 1.0000 - val_loss: 4.4462 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 0.82759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVualffJJ118"
      },
      "source": [
        "# Load wights file of the best model :\n",
        "wights_file = './BestWeights.hdf5' # choose the best checkpoint\n",
        "NN_model.load_weights(wights_file) # load weights\n",
        "NN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jboGZBt_KBJT"
      },
      "source": [
        "predictions = NN_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgh2gRclKDWC"
      },
      "source": [
        "# round predictions\n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "predictions = rounded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhQl1kplKFvS",
        "outputId": "8a8679c6-631a-4c0f-c9c4-74e5c774ae56"
      },
      "source": [
        "score = accuracy_score(y_test ,predictions)\n",
        "print('Test Accuracy:',score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7708333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGJtedgKKYP"
      },
      "source": [
        "## **Other Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBM2QLYlKNMi"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTEBco7EKbYx"
      },
      "source": [
        "names = [ 'Neural Network',\n",
        "          'Logistic Regression',\n",
        "          'SVC',\n",
        "          'Gradient Boosting Classifier',\n",
        "          'Extra Trees Classifier',\n",
        "          'Bagging Classifier',\n",
        "          'AdaBoost Classifier',\n",
        "          'Gaussian NB',\n",
        "          'MLP Classifier',\n",
        "          'XGB Classifier',\n",
        "          'LGBM Classisfier',\n",
        "          \"K Nearest Neighbour Classifier\",\n",
        "          \"Decison Tree Classifier\",\n",
        "          \"Random Forest Classifier\",\n",
        "         ]\n",
        "classifiers = [\n",
        "    NN_model,\n",
        "    LogisticRegression(),\n",
        "    SVC(),\n",
        "    GradientBoostingClassifier(),\n",
        "    ExtraTreesClassifier(),\n",
        "    BaggingClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    MLPClassifier(),\n",
        "    XGBClassifier(),\n",
        "    LGBMClassifier(),\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "        ]\n",
        "\n",
        "# Zipped all architecture\n",
        "zipped_clf = zip(names,classifiers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-SWlR1iKdwz"
      },
      "source": [
        "import warnings\n",
        "# untuk menghapus warning\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# fungsi accuracy testing\n",
        "def acc_summary(model, train_X, train_y, val_X, val_y):\n",
        "    t0 = time()\n",
        "    model.fit(train_X, train_y)\n",
        "    pred_y = model.predict(val_X)\n",
        "    train_test_time = time() - t0\n",
        "    accuracy = accuracy_score(val_y, pred_y)*100\n",
        "    print(\"accuracy : {0:.2f}%\".format(accuracy))\n",
        "    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
        "    print(\"-\"*80)\n",
        "    return accuracy, train_test_time\n",
        "\n",
        "# fungsi komparator\n",
        "def classifier_comparator(train_X,train_y,val_X,val_y,classifier=zipped_clf):\n",
        "    result = []\n",
        "    for n,c in classifier:\n",
        "      if n=='Neural Network': # for only neural network\n",
        "        predictions = NN_model.predict(x_test)\n",
        "        # round predictions\n",
        "        rounded = [round(x[0]) for x in predictions]\n",
        "        predictions = rounded\n",
        "        score = accuracy_score(val_y, predictions)*100\n",
        "        print(\"Test result for {}\".format(n))\n",
        "        print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
        "        print(\"accuracy : {0:.2f}%\".format(score))\n",
        "        print(\"-\"*80)\n",
        "        result.append((c,n,score,train_test_time))\n",
        "      else:\n",
        "        checker_pipeline = Pipeline([\n",
        "            ('classifier', c)\n",
        "        ])\n",
        "        print(\"Validation result for {}\".format(n))\n",
        "        #print(c)\n",
        "        clf_acc,tt_time = acc_summary(checker_pipeline,train_X, train_y, val_X, val_y)\n",
        "        result.append((c,n,clf_acc,tt_time))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz7kn2n9K7QQ",
        "outputId": "94cb37c6-e88f-43e6-9c85-a3c811bb4c66"
      },
      "source": [
        "result = classifier_comparator(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation result for Logistic Regression\n",
            "accuracy : 80.21%\n",
            "train and test time: 0.01s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for SVC\n",
            "accuracy : 77.60%\n",
            "train and test time: 0.01s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Gradient Boosting Classifier\n",
            "accuracy : 81.25%\n",
            "train and test time: 0.16s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Extra Trees Classifier\n",
            "accuracy : 79.69%\n",
            "train and test time: 0.16s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Bagging Classifier\n",
            "accuracy : 76.56%\n",
            "train and test time: 0.03s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for AdaBoost Classifier\n",
            "accuracy : 78.65%\n",
            "train and test time: 0.10s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Gaussian NB\n",
            "accuracy : 76.56%\n",
            "train and test time: 0.00s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for MLP Classifier\n",
            "accuracy : 80.21%\n",
            "train and test time: 0.70s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for XGB Classifier\n",
            "accuracy : 79.69%\n",
            "train and test time: 0.09s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for LGBM Classisfier\n",
            "accuracy : 79.17%\n",
            "train and test time: 0.07s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for K Nearest Neighbour Classifier\n",
            "accuracy : 80.73%\n",
            "train and test time: 0.01s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Decison Tree Classifier\n",
            "accuracy : 72.40%\n",
            "train and test time: 0.00s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Random Forest Classifier\n",
            "accuracy : 78.65%\n",
            "train and test time: 0.20s\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSHXyPeMLcnQ"
      },
      "source": [
        "## **Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEf-MVn7Ld9A"
      },
      "source": [
        "# Plotting models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOYIUp28Lfdx"
      },
      "source": [
        "# get name and score models\n",
        "n = [v[1] for v in result]\n",
        "s = [v[2] for v in result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1qLku8oKLg9w",
        "outputId": "302aaf81-cf14-4b49-c98e-ff3378696898"
      },
      "source": [
        "# Visualisasi model\n",
        "plt.figure()\n",
        "sns.barplot(x = n, y = s)\n",
        "\n",
        "plt.title(\"Plotting Test Result\")\n",
        "plt.xlabel('Model Name')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=10)\n",
        "plt.yticks(size=10)\n",
        "plt.ylabel('Accuracy Score')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9tbblNJLvKX"
      },
      "source": [
        "## **Feature Importance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T3PAj9tLw_g"
      },
      "source": [
        "# get best models [-1] is random forest and next [0] is index to model to get feature importance, and zipped with X column\n",
        "importances = sorted([(a,b) for a,b in zip(result[-1][0].feature_importances_, x_df_transformed.columns)],reverse=True)\n",
        "n = [ni for si,ni in importances]\n",
        "s = [si for si,ni in importances]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "1cmcBnH-LzNW",
        "outputId": "26c18996-bf9d-4908-9555-14bf0ef748f1"
      },
      "source": [
        "# Plot the feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(n,s)\n",
        "plt.xticks(rotation=45, ha='right', size=10)\n",
        "plt.yticks(size=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFiCAYAAAD4JRNmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7hcZbXH8e+PhEBoQUIo0kKHIKDcAF6VIj20IAJSREAELChdkCYgKChSFCyoWEClxEKQCKJYEZBQBAFzifSIgIAova37x3rHbIZDMknOmT3Z+X2e5zyZXU5mTTlrv/utigjMzKy55qo7ADMzG1hO9GZmDedEb2bWcE70ZmYN50RvZtZwTvRmZg3nRG9zNElHS/pm3XGYDSS5H73NLEn3AYsDr1R2rxIRf5/F//NDEfHLWYtu9iPpBGCliHh/3bFYs7hEb7Nqu4hYoPIz00m+P0gaXOfzz6zZNW6bPTjRW7+TNEzStyQ9LGmKpJMlDSrHVpR0jaTHJf1T0vclLVyOXQAsC1wu6WlJn5S0saSH2v7/+yRtVh6fIGmcpAsl/RvYe1rP30esJ0i6sDweKSkk7SPpQUlPSvqwpHUl3SbpX5LOqfzu3pKulXSOpKck/VXSppXjb5Y0XtITkiZL2q/teatxfxg4Gnhfee1/LuftI+kuSf+RdI+kAyr/x8aSHpJ0mKRHy+vdp3J8qKQvSrq/xPcHSUPLsbdL+mN5TX+WtHHb67qnPOe9kvaYwa+A9RiXImwgfAd4FFgJmB/4GfAg8HVAwOeA3wELAT8CTgAOjog9JW1ApeqmmoCmYSywM/ABYB7gB9N4/k6sD6wMbAiMB64ENgPmBm6RdGlE/LZy7jhgUWBH4MeSlo+IJ4CLgL8AbwZWA66W9LeIuOYN4l6U11fdPApsC9xT4vm5pBsj4uZyfAlgGLAUsDkwTtJPI+JJ4HRgDeAdwD9KrK9KWgq4AtizvLZNgR9JWg14FvgSsG5ETJK0JLBIh++b9SiX6G1W/bSUCv8l6aeSFge2JhP3MxHxKHAmsCtAREyOiKsj4oWIeAw4A9hoFmO4LiJ+GhGvkhePN3z+Dn0mIp6PiF8AzwA/jIhHI2IK8HvgbZVzHwXOioiXIuJiYBKwjaRlgHcCR5b/61bgm2RSf13cEfFcX4FExBUR8bdIvwV+AWxQOeUl4KTy/BOAp4FVJc0FfBA4KCKmRMQrEfHHiHgBeD8wISImlOe+GphY3jeAV4G3SBoaEQ9HxB0z8N5ZD3KJ3mbVDtWGU0nrkSXfhyW1ds9FlqgpF4KzyWS1YDn25CzG8GDl8XLTev4OPVJ5/Fwf2wtUtqfEa3s03E+W4N8MPBER/2k7NvoN4u6TpDHAp4FVyNcxH3B75ZTHI+LlyvazJb5FgXmBv/Xx3y4H7Cxpu8q+uYFfR8Qzkt4HHA58S9K1wGER8dfpxWq9yyV6628PAi8Ai0bEwuVnoYhYoxz/LBDAmhGxEFm6VOX327uBPUMmNwBKXfuItnOqvzO95+9vS6lyRSHbGP5efhaRtGDbsSlvEPfrtiXNQ1ZtnQ4sHhELAxN47fv1Rv4JPA+s2MexB4ELKu/PwhExf0ScChARV0XE5sCSwF+Bb3TwfNbDnOitX0XEw2T1whclLSRprtIA26qeWZCsXniq1BUf0fZfPAKsUNn+P2BeSdtImhs4lqzPntnn72+LAZ+QNLeknYHVyWqRB4E/Ap+TNK+ktYB9gQun8X89Aows1S4AQ8jX+hjwcindb9FJUKUa63zgjNIoPEjS/5aLx4XAdpK2LPvnLQ27S0taXNJYSfOTF8ynyaocm4050dtA+ACZpO4kq2XGkaVDgBOBdYCnyAbBH7f97ueAY0ud/+ER8RTwUbJ+ewpZwn+IaZvW8/e3G8iG238CpwA7RcTj5dhuwEiydP8T4NPTGR9wafn3cUk3l2qfTwCXkK9jd7JxuFOHk9U8NwJPAKcBc5WL0Fiyl89jZAn/CDIfzAUcWmJ+gmw/+cgMPKf1IA+YMptJkvYmewi9q+5YzKbFJXozs4ZzojczazhX3ZiZNZxL9GZmDedEb2bWcD05MnbRRReNkSNH1h2Gmdls5aabbvpnRLQPKOzNRD9y5EgmTpxYdxhmZrMVSff3td9VN2ZmDedEb2bWcE70ZmYN50RvZtZwTvRmZg3nRG9m1nBO9GZmDedEb2bWcD05YGpWjDzqitqe+75Tt6ntuc3M3ohL9GZmDedEb2bWcE70ZmYN50RvZtZwTvRmZg3nRG9m1nBO9GZmDedEb2bWcE70ZmYN50RvZtZwTvRmZg3nRG9m1nBO9GZmDedEb2bWcE70ZmYN11Gil7SVpEmSJks6qo/jG0q6WdLLknaq7H+rpOsk3SHpNknv68/gzcxs+qab6CUNAs4FxgCjgN0kjWo77QFgb+AHbfufBT4QEWsAWwFnSVp4VoM2M7POdbLC1HrA5Ii4B0DSRcBY4M7WCRFxXzn2avUXI+L/Ko//LulRYATwr1mO3MzMOtJJ1c1SwIOV7YfKvhkiaT1gCPC3Gf1dMzObeV1pjJW0JHABsE9EvPoG5+wvaaKkiY899lg3wjIzmyN0kuinAMtUtpcu+zoiaSHgCuCYiLj+jc6LiPMiYnREjB4xYkSn/72ZmU1HJ4n+RmBlSctLGgLsCozv5D8v5/8E+F5EjJv5MM3MbGZNN9FHxMvAgcBVwF3AJRFxh6STJG0PIGldSQ8BOwNfl3RH+fVdgA2BvSXdWn7eOiCvxMzM+tRJrxsiYgIwoW3f8ZXHN5JVOu2/dyFw4SzGaGZms8AjY83MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhBndykqStgLOBQcA3I+LUtuMbAmcBawG7RsS4yrG9gGPL5skR8d3+CHx2NPKoK2p77vtO3aa25zazek23RC9pEHAuMAYYBewmaVTbaQ8AewM/aPvdRYBPA+sD6wGflvSmWQ/bzMw61UnVzXrA5Ii4JyJeBC4CxlZPiIj7IuI24NW2390SuDoinoiIJ4Grga36IW4zM+tQJ4l+KeDByvZDZV8nZuV3zcysH/RMY6yk/SVNlDTxscceqzscM7PG6KQxdgqwTGV76bKvE1OAjdt+9zd9nRgR5wHnAYwePTo6/P+tn7ih2Ky5OinR3wisLGl5SUOAXYHxHf7/VwFbSHpTaYTdouwzM7MumW6ij4iXgQPJBH0XcElE3CHpJEnbA0haV9JDwM7A1yXdUX73CeAz5MXiRuCkss/MzLqko370ETEBmNC27/jK4xvJapm+fvd84PxZiNHMzGZBzzTGmpnZwHCiNzNrOCd6M7OGc6I3M2s4J3ozs4ZzojczazgnejOzhnOiNzNrOCd6M7OGc6I3M2u4jqZAMKuTZ9Y0mzUu0ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcE72ZWcM50ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcE72ZWcN1lOglbSVpkqTJko7q4/g8ki4ux2+QNLLsn1vSdyXdLukuSZ/q3/DNzGx6ppvoJQ0CzgXGAKOA3SSNajttX+DJiFgJOBM4rezfGZgnItYE/gc4oHURMDOz7uikRL8eMDki7omIF4GLgLFt54wFvlsejwM2lSQggPklDQaGAi8C/+6XyM3MrCOdJPqlgAcr2w+VfX2eExEvA08Bw8mk/wzwMPAAcHpEPNHXk0jaX9JESRMfe+yxGXoRZmb2xga6MXY94BXgzcDywGGSVujrxIg4LyJGR8ToESNGDHBYZmZzjk4S/RRgmcr20mVfn+eUapphwOPA7sCVEfFSRDwKXAuMntWgzcysc50k+huBlSUtL2kIsCswvu2c8cBe5fFOwDUREWR1zSYAkuYH3g78tT8CNzOzzkw30Zc69wOBq4C7gEsi4g5JJ0navpz2LWC4pMnAoUCrC+a5wAKS7iAvGN+OiNv6+0WYmdkb62hx8IiYAExo23d85fHzZFfK9t97uq/9ZmbWPR4Za2bWcE70ZmYN50RvZtZwTvRmZg3XUWOsmfVt5FFX1Pbc9526TW3PbbMXl+jNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4bzwiFlDeVEUa+moRC9pK0mTJE2WdFQfx+eRdHE5foOkkZVja0m6TtIdkm6XNG//hW9mZtMz3UQvaRBwLjAGGAXsJmlU22n7Ak9GxErAmcBp5XcHAxcCH46INYCNgZf6LXozM5uuTkr06wGTI+KeiHgRuAgY23bOWOC75fE4YFNJArYAbouIPwNExOMR8Ur/hG5mZp3oJNEvBTxY2X6o7OvznIh4GXgKGA6sAoSkqyTdLOmTsx6ymZnNiIFujB0MvAtYF3gW+JWkmyLiV+0nStof2B9g2WWXHeCwzMzmHJ2U6KcAy1S2ly77+jyn1MsPAx4nS/+/i4h/RsSzwARgnb6eJCLOi4jRETF6xIgRM/YqzMzsDXWS6G8EVpa0vKQhwK7A+LZzxgN7lcc7AddERABXAWtKmq9cADYC7uyf0M3MrBPTrbqJiJclHUgm7UHA+RFxh6STgIkRMR74FnCBpMnAE+TFgIh4UtIZ5MUigAkRUV/nXjPrCe7j310d1dFHxASy2qW67/jK4+eBnd/gdy8ku1iamVkNPAWCmVnDOdGbmTWcE72ZWcM50ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcV5gyM6to4qhdl+jNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGs6J3sys4ZzozcwazonezKzhnOjNzBquo0QvaStJkyRNlnRUH8fnkXRxOX6DpJFtx5eV9LSkw/snbDMz69R0E72kQcC5wBhgFLCbpFFtp+0LPBkRKwFnAqe1HT8D+Pmsh2tmZjOqkxL9esDkiLgnIl4ELgLGtp0zFvhueTwO2FSSACTtANwL3NE/IZuZ2YzoJNEvBTxY2X6o7OvznIh4GXgKGC5pAeBI4MRZD9XMzGbGQDfGngCcGRFPT+9ESftLmihp4mOPPTbAYZmZzTk6WUpwCrBMZXvpsq+vcx6SNBgYBjwOrA/sJOnzwMLAq5Kej4hz2p8kIs4DzgMYPXp0zOgLMTOzvnWS6G8EVpa0PJnQdwV2bztnPLAXcB2wE3BNRASwQesESScAT/eV5M3MbOBMN9FHxMuSDgSuAgYB50fEHZJOAiZGxHjgW8AFkiYDT5AXAzMz6wGdlOiJiAnAhLZ9x1cePw/sPJ3/44SZiM/MzGaRR8aamTWcE72ZWcM50ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcE72ZWcM50ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcE72ZWcM50ZuZNZwTvZlZwznRm5k1nBO9mVnDOdGbmTWcE72ZWcM50ZuZNZwTvZlZw3WU6CVtJWmSpMmSjurj+DySLi7Hb5A0suzfXNJNkm4v/27Sv+Gbmdn0TDfRSxoEnAuMAUYBu0ka1XbavsCTEbEScCZwWtn/T2C7iFgT2Au4oL8CNzOzznRSol8PmBwR90TEi8BFwNi2c8YC3y2PxwGbSlJE3BIRfy/77wCGSpqnPwI3M7POdJLolwIerGw/VPb1eU5EvAw8BQxvO+e9wM0R8cLMhWpmZjNjcDeeRNIaZHXOFtM4Z39gf4Bll122G2GZmc0ROinRTwGWqWwvXfb1eY6kwcAw4PGyvTTwE+ADEfG3N3qSiDgvIkZHxOgRI0Z0/grMzGyaOkn0NwIrS1pe0hBgV2B82znjycZWgJ2AayIiJC0MXAEcFRHX9lfQZmbWuekm+lLnfiBwFXAXcElE3CHpJEnbl9O+BQyXNBk4FGh1wTwQWAk4XtKt5Wexfn8VZmb2hjqqo4+ICcCEtn3HVx4/D+zcx++dDJw8izGamdks8MhYM7OGc6I3M2s4J3ozs4ZzojczazgnejOzhnOiNzNrOCd6M7OGc6I3M2s4J3ozs4ZzojczazgnejOzhnOiNzNrOCd6M7OGc6I3M2s4J3ozs4ZzojczazgnejOzhnOiNzNrOCd6M7OGc6I3M2s4J3ozs4ZzojczazgnejOzhuso0UvaStIkSZMlHdXH8XkkXVyO3yBpZOXYp8r+SZK27L/QzcysE9NN9JIGAecCY4BRwG6SRrWdti/wZESsBJwJnFZ+dxSwK7AGsBXwlfL/mZlZl3RSol8PmBwR90TEi8BFwNi2c8YC3y2PxwGbSlLZf1FEvBAR9wKTy/9nZmZdMriDc5YCHqxsPwSs/0bnRMTLkp4Chpf917f97lJ9PYmk/YH9y+bTkiZ1ENtAWBT458z8ok7r50hez7HNHMc2cxzbzKkztuX62tlJou+KiDgPOK/uOCRNjIjRdcfRF8c2cxzbzHFsM6cXY+uk6mYKsExle+myr89zJA0GhgGPd/i7ZmY2gDpJ9DcCK0taXtIQsnF1fNs544G9yuOdgGsiIsr+XUuvnOWBlYE/9U/oZmbWielW3ZQ69wOBq4BBwPkRcYekk4CJETEe+BZwgaTJwBPkxYBy3iXAncDLwMci4pUBei39pfbqo2lwbDPHsc0cxzZzei42ZcHbzMyayiNjzcwazonezKzh5qhEL2lY3TGYmXXbHJPoJa0EHC3pXXXHMrsoo5utYWanz7WXYm2PRdJskz9nm0BnhaS5gWfJXkNjJL295pBeo5e+zC2SVLrIImlFSctM73fq0HrvJM1bdyxVvfiZwus+16UkvanumFoqn+XSkoZKGhoR0QvvZdv7tpukZSLi1brj6lTjE72krcnunwJOBwIY20vJvnyZN5N0qKQxkob2QkwAkj4JfBn4jqQTJS1Wb2RTtf74JG0H/FDSAnXHBK9LCqtJWrXumFoqcR0BnANcLOmAXqjWLJ/lGOBHwKeACyUtED3QNbDyvh0MHAEsVG9EM6bxiR7YHngvcAz54XwZeIUeSPaVEsxawNnAKsAOwPGS5q8zNgBJWwDvjoitybmMRgGP1RvVVCUxbAV8Bjg7Ip4uI7NrI2muSlI4hJwE8BclsdYZlyqPxwKbR8R7gBeBd0bEU7UFV5S/g88CewLPA0uQd+Gt47WW7CWtCewCbFjGCG0gabaYpHFOSPTfAH4G3AMcBCzM1GS/naQN6gqsJKpNgJOBD0XEh4ELgXmBY7ud7Pv4QwpggqTjyD+6PUrMa3czrul4G3AScL+kXYCfSdpd0oJ1JIbW7bykDYF3A/8DbAHsIunwbsdTYqneYQwCngQuKhefwcCHyrEV6oiv4lXgq8CyZIFnz4h4StI7JM3d7ZJ928VxbvLi829gX0lfB44j74je3c24ZkYjE72k5SQtWTbvIr/MKwN3AAeTJfsvAfMB7665fvdFYFtg67J9PTnV88LAid1q8GlLBpuV3f8h74jeCewQES9K+jjwhbruOPpI3o8A+5EXyGWAG8j3c0g3E4OkNVUW5ZG0HPAR8jNcMCImAXsDO0s6vlsxtVQ+108AVwALAPsAmwDblc/1EOA0SfN0O77SVvBmMokeT1a1bhQR90jaiCygLdLlmKp/D3sDH4+Iu4FryRl4vxMRWwDfA9btZmwzJSIa9UOWoF4lE+amwPxkCeFksmR1LLmQyqrACGBEl+NrjUZeChheHo8Gngb2KtuDgQ2A1Wt4/w4E/kxOQCfyVvob5AXyEOA2YI2aPtvWe7dN+Tw/T16s1wSWKcdWIOdTWrnLsS1F3vW8pbxvGwM/AD7c+o4BawO/ARap4b3bFvh567mBb5MLBO1BTg/+525+rpXPcn1yTqzjgXnIatY/Au8jS/W3AmPr+L6V+A4q36dRfRzbgyw8dvW7NlOvo+4ABuCDmR+4AHiUnHPiSODrwFnAWuWP8RTgi8DcXY6t9eXeHvg1cA1wKlk3/1ay/nu/Gt+7TYCJlQvQcmSpdK/yh3g6sFrNn+/m5ER7bwH+CpxfeV93AG7vZmIgS3Onl8dzA5eQjZwiV1U7lyzdL17OGVLT+3Yc8BxZvwywOHAouSLc1/pKZF2IaWvgd+XvdBLwsXKh3qwk/68AW5dzVUN8S5DVvgsDbwJ2K7lleWD1EnsthZ4Zfi11B9CPH8qildLKULJq5vdkaf40ctGT1h/kqq1k1qXYBlceL0spFZMl+QPIEvNCZCnwWbJ0OFcX4lLbv9uW923ncgGaBFzN1NLyoBo+1yWAt1a2Tynv2zbkbfSylWM7ko3HXUsM5Y/+euC0sr1y+TzPKMl+C3L1tQ+RVaVdTVhkw+ai5fFnSuJap/q9rOPiQy5M9HNgk7K9JXAxWTBT27nd+ixf9zzkhXoyWUVzGllo/Ek59qZuv28z/drqDqCfPqCtydurS4BTyr6FyHrb75XtpanhFgt4M3AUME/ZXg34beX4SLKUsFPZ7soFqPqlLsl0SPn5XvnZshy7ANi5/Xe6FONg4P3lPZu/7DuWrBK5uvV5kiWtj3U5trkqj0cCv60k+xXJO40vlGS/KbBEt797JZbzgL8ztRB0FPBjYHRf34UBjGNVclbbZdpi+xilAAF8gOzdtWf7e9yF+Kp/D7uT1Vk7kIXG3YEly7HNyt/E4G7F1i+vr+4A+uED2gr4A7k+7VvLhzC0HBtSksJF3U5SlfiGkNUMSwNLlX0/Ao6snHM8cEx53CpldasU89Hy/l0KnNF2bHvy7mNkjZ/v/GRbyjeBdcgunv8keykBvJ2cBnuzmuJ7a/l3JFn//oWyvQKVgkcNcQ2vPD4duI+pJfsTy9/FPF2KRWRV6UvAD8muxAuU796RZMMr5bP9NfAXaqoiJKuzfgXsC9wE7FY5dghwM7BWHbHN0uuqO4BZ/FAWIRte31O21wMeJuv2vl72DSHr+y5sfem6FNsgyi1x+aKfT95hLE3WM59N3qpuQ94abljD+zcGuIUsbS1FthlcVo7tSN4lrVnTZztX+Xc+so70WLIueQXgHWTj4QXAdWTPka7HV75/rwCfLPtayf7UyvaSXYqnWiLdmGyorlZ5fQm4l6ntL12ruizPtzlZoFgRuIysgvsGeQE/u1x47iqf7xep4cJNrox3fnl8JNlDaVC5KC0MfBp4S7fj6pfXVncA/fDhbFOS1drk7fyJTO1md1E5Z37gzV2MaQh52zcSeA9ZYh9aEtNZZD3u8mRJ6xRKg1MX4mqv+9wU+Fzbvl+SPX7mpdyB1PCZttoMxpB1ykNKgji8JIblyx/fYsAKfb22LsQ4d/l3LeAfwOFlezmyp8iJ3X6/yuPhwJJkr5rjKKVPshrsXrJHS9eqRNri/ClwXHm8D7ms6B0lsZ9T/l42Bv6PLtxF9vH3MAz4CVm1dRlTC2p7lvxSS61Av7zWugPopw9sK7Jkf1Rl3wLkLVhXSy6V59+tlFAmAWPKvnmB75MlmFad32saRAcwnmoyGEuWnDYof1TLVY59FdiqBz7Td5cksEVl34rk7fMF1HAHVIljU/ICPqxsr072AT+4bC9bfU+7GNdHgG+VxyuTdeAnkne6u5THy9cQV+s7vi7ZILw2WT3zofJeHk92kV2VvFMb8FJz29/DasBi5fEHS2yt3kl7k1WDyw50TAP6eusOoB8/uM1LUl24bO9TSi8LdjmOVpXDAiWp30jWPbYaE+ch68PPp0t1pG3xHUzeQq9Wtj9JNoC9rxy7BVixBz7PjwD7tN6zyv5lydvqrlUptV+EgU+QDdbbUHpekA2Jr7ZiruH9+mD5ri1X2bcwOQ7i4nJB7/q4jLYYFyOXJH0OOKCyf77K48W7HNNBZF38neRd+JpkA/EksmrpdmaTLpTTfJ11B9DPH9qYcjX+KNnHtav1aZWSy7vJuXUWIAfMXMnUBqdFyHrnrtf1lRLTtbTd5ZRSyynk7X7X+1O/QayfIhvmqkl+Y7KNo2vdPHltye8DwAfK44PIEZzbVb57Z9OlRsS2uAaR7Rc7kNWWB5NtF63qpKGUEmvdP2Sp/jqm3tHOVf23y7GMIatoBpN3PD8huxbPT96lrQUsXfd71i+vte4ABuDD25acVqCu0ZtbAndT+geXfQeTfYaPIKcV6EpplNeXRNcmG1hbdY+teuZ5y7911d22LpBvJauVVC6IXyBv9ecrCeIOaqqyIXtj3FD9XpXEfwFwOW1VYN36XMmR4EOB7YDHyXrwg8tF8Xd0sW2qw9jnJttZdun2943Xdoldgbzjvqayb6eS+PelcpfRhJ9GLg4uab6IeLbLzymyWuZsckDFlZKGRMSL5fh7yBGwt0TEL7oc29bk7emj5ICP64CLI+LZMo/HO4CPAy9GTV+IMr/OV0qMj5MJfn6yH31rWoHPRsT4GmJbhkxO25PtLJsB/0vetY0gb/fvjojJXY7rMHIMyb4RcZ+k1YAHyue6GVknPyYi/t3NuKZH0rpkIeOPNT3/tmRhbFUyqf86Is4qx3Yj74z267X3bVY0MtHXqcxqdz/Zxa41k+FbgHsj4pnKeRqopFqZp73176Vk0twH2Ijse746WTXyQbJ76l0DEUuH8a5Olt4Pi4hJks4o8X41Im5tzYEfEY8O5PtWied1zyHpx2S1yF+Ap4CVyAvS3nVcHCXtSPZC2iQinpe0PHmnNknSgeSI6z0i4rZux9ZrJL2D7EF2adn+HTmnzhPkxXsz4P8i4uxyfMGI+E9d8Q6ERs5e2S2V+eSXlrRi2X0lOS/G28uxdcgulctWf3cgk0Pl/x5RtncmZ3k8m2yIPQOYQE6kNrbmJD8f2WtqLbLqhog4lOzFcrSkdSLi0Yh4tBzrWpKXtLWk7ZULwbyfbIA9KSIOJrsD/ocu/Q31MWvni+RgtvdL+gzwHeDLZY2Fv5Kjmef4JF8sSs7MuXPZnoccVPkK8Avyb3YdSR8rx5+uIcYB5RL9LCq3gWeSfYLvjIiPSjqWTFpDyLrAYwhmjzYAABW4SURBVCPip12IZR2yVHd9KcW8F7g0Iq4vxy8ip2TYqZU469BeYpa0IDlr5orADyPiV2X/mcC3u5GwWom0kuT3AQ4j527/M/DdiLixHDuYrJ/fu1uxVeJagey3vwJZL785OQfL38hG9Ql1VYn0mvaLNjl/09HkjJlfIqsqn5K0LLmuwfUR8UhtAQ8gJ/pZIGllcrrc08juWTcDv4yIT5TqhjWBhyPizoGuciilzr3IXgOHk9MEHAw8A/wsIv4kaQg5uduPyblhXhmoeKYRZ6s6aWuy4fUJsqR8P9mlcmXgpxFxZZfjGhwRL5fH25C9pbYne2R8miwFXkGWoo8jR1De3uUYDyMbWZ8gu1JeAPwnIl4tpdXjyTu0e7oZVy9qS/KrkwsPbUYWylYiv3MjyQv5k8AnIqJxJfkWV93MJEmLkCWE4cDjEfE8WYrfWNJFpbrhVxFxJwxslYOkd5H94O8jh5KfRHbt/AKZoLaXtD75Rf8ROflW15M8/HdVrW3IxtbvkyXTS8lBK18GHiBXYxreR3XFgJC0KDC5fKaQPVk2AtaLiJfIKq8XyJ4iK5HdFgc8yVdfv3It1a0jYjvyruxtZPXWApK2JBuGd3OST5UkfwhZzTY8Iq4g+8jfRvag2oy8MzuhyUkeaF73ym78kA2Zw8iRpT8hS9KtfsHzkHWkXRkyTdZv30oO096QnLXzYLLL31vImSmPIQeq3En9g2aGkr1BViNL9L8j+8zfVd6zealn9OZ25XNrjXb9bPlsW1MILE6WmLvSH7363SEv2u8hx4d8jKxTbnWRXYkcW9DVgUa9+sNrpwTfhpxCerG2c8aQd7Y71R1v196XugOY3X6ABcmS/LdKUt2ULJnuydTZKbs1cdpG5IRo67ftfzdZwr+8kqgWob6pcvuaU2Q5cuTy6mXfDeRcLF0dydwW19bl/RxGduc8mrwDas3f3pV+321J/gCyiuYdZLfY31SOHULOdV/LYia99lMKYB9hapX09kydtnyB1ntLVsdtQZknaU74cdXNDIrsdjWOnCXzs+QApPPJ2R43L/Xg3fI24MsRcUNrh6TPk9Myr0H2/f6ypPUj4omI+EcXY/uviFwEXdI+kraJiKfIeua7gaeVC7T/gaxfrq1bW0RMIKc3mEhexD9H3mkcVtZS7UqDVrQykrQHWb3wKbJkeiNwraQPSvogeSf5hShjNYz5yamhV5e0MDnVwhYAMbVqZjdyNPMvYg6q5hpcdwC9TNIa5JfiVOVK75tGxLERMVHSK2TD54nkFLqDgEe78UdXaWhakezT3do/hqyq2YG8y5hCTmvw94GOaVpxSvof8g7oMmBpSe+IiGMkvUheLDcnB6jU3h0wIiaUqvHrgf+NiGMlDY+IFwb6uSVtQlbFPUAuZLIo2XPqpIh4SNI5ZI+RjYDngfdHxF8GOq5e1/qelb/LRcmqy0ci4jhJ75F0E9mAvgpZ4h9bZ7y1qPuWold/yC/Fn4ADy/ayZOv8Zyrn7EROAvYV6llmb1NyauZW1cLcTK27PZqsvul6XG0xbkSOI2gtGbcW2eunNQ/LEkytvumZaWDJi+VN3YqJnDrjFrKR+nTyojiSnFf+T5Q5V5g6N0xX1zvu1R/6qE4D3kl2nzy6bB9Cdky4kJrbqGp7n+oOoBd/yAauKcD2ZXsoOQPl4mTp+KSyfz2ypFrXvDrzAyeUZLBeZf9uZP131xs1+4hxL3Jg0YfL9iCy2+lVlKX3evWHUq/bhedZh7wzG122lyfvyN5Vtk8mG62X6UY8s8sPZXnE8nh/cpnEPcr2uuR6r5+izFvDbLb8X3/+uI6+b0uSvWdac11cQrbQP0KOeN1H0gVkr4xxEXFHHUFGTqnwDXIk3+clnSnps2R10oci4t464gKQtJqkHSPiu+RgqEMlrRvZrfNOcoK3i+uKrxPRvS53k8gBTzuV572XvIgvVo4fT7YbfEPSoC7F1NPKlA8TJW0gaSOybeVVYDtJp0cObjufHJdxiKS5yNXA5kgeMPUGJG1KThUwP7kM4QmVY4uSpdKnIuLmeiKcqgyWWoes655C9sy4u4Y4WnXyG5PJaUVyIMplkvYjb6H3i4hrux1bL5I0mqzS+rykhcjh+H8EniXHZLwnsh9/q0/9ohHxWG0B94jSFjUvWSA7mGzP+FpE3CRpVfIu98GI+KSktwF/j4aOeO1Y3bcUvfTD67sBbkZ2+dupbA/CdaPTew/fRU789U6ybv4ipq7peyA5QnFY3XH2wg+ZzK9jajvQMHJVtAcq5/j79tr3bIvy/dqgbO9C9on/aNmei5yV8mfAyXXH2ys/7nVTVEqj7yAbYu8mF8v+IHCGpPkjqyHm2Nu/aan0BHo7Ocf3tWRXwAOBk8rhcySNj+xeOceqzKtzq6QfAPtJWjKyJ9L2wC8lnRoRR0Up0RuUEcCXkl2Kf1++c5eU6qyTJU2KiF9Jupss6T9Xa8A9xHX0RUnyW5LdEYeQg432jIhfk5NbHVcmurKKyjD91r83A8NK11Qi4hyyOum9klaKiAe6NbVBr4pC0sfJEuqlwF6Sjoxsd9kS2EHSabUG2kMkbUV2OjgLWFHS7qVgQUT8kGyXOlfSmIh4NSImR8SUGkPuKS7R899ktRCwBzmabhi5jupVABFxjXIK064uZtLrKndB7wbWlnQfOTnZ08AWkpYAHiO/Z/OSdfQfa/2Bzqla9e1k4+shEXGzpMuB85RzoR+rXJxjeK2B9oDyXi1IjhD+SET8UTmB216SXo2IiwAi4ntlUNspkn4bXV54qNe5MbZC0uHkHCxrAbtErtqzKzApIm4p5wz4whezE0mbk5ORHUkOxz+EXPJvc7IaZzFgP3I+lk2BI6IsyDIn6et7o1yk5pfAFZGrQo0le3LtHxHfrCPOXiNprsjZOYe1qvxKw/Xm5LTM328l+9axaNDKUP1lji3RV0qjy5Brpt5NzlD4P8DHS5J/G9mCv3/r95zkX5e0diLvhETOnvmLiJgiqTXKdT6ygfYkcmHtOTrJS1qLHNh2Czm9wkZke9Ct5GIiPyZ738zxyvvW+r78N1dFxL8ltd6j90uaNyK+U7YbtTJUf5mjS/SStiMT+d1kvfynyJJpkFU5KwPHRw3rlPaqygVye7Lu/a1kSX0lclWj+yW9H3gyIq4oDWVfIru/dXX+9l4j6SByOceHye/YseRFckny+7Yc2cNrUm1B9oi2i+PHyN41vwF+HBF/LvsXBLYlq1sPcEn+jc2xiV65kPI3yMnINgNOjIhVlJOSrUYOzf9HRNzm6ppUSfJvJ4fpH0POjX44Odz8Kklrk3PiHxQRv6wx3J5SSvJfA7aJiCclnUDOxX8QedezAnB/RDxQX5S9o1Jl8x6yiuZMcpT1P8hVtH5fzluAzGMuyU/DHJnoJS0H/AvYnSxZ7Q3sHhH3KCfc8lJsFaVRdT6ykfVZcqTwvyNi13L8C2Tj4uLkOrUnR8RlNYXbE9oLB+U9/ApwVET8X9k3DrgjIj5dU5g9RznK9U8R8Vy5OP4A+FJEnCdpKeDj5N/s1RFxTZ2xzk7muDr60kPkbHJejB2Bhck5bR4uX7IzJe0SEZPrjLNXlDufC8gL4/3krI7fJ/vG7xoRF0XEEWVE4lDguYiYNCffBbVVOwwj6+QfIafUWEfSU5EjNX/LHPg3OB3vBO6V9BA5VcZvgY9I+kPkkpxnkVVeG0q6LiLcV74Dc1SJviSjLwOfi4hfK+f0/ijwVbIL14fIEtfPagyzZ0gaRSb1Q8l2jLHkPPefATYhJ0/7TkSMqy3IHtOW5A8je4csTfYBf4ZcoOYfZMPrJsD7oqa5knpJq6qmPH4LOVhx+Yh4RtJx5BQfx5RkvxhA1LjA/eym8QOm2gbnvIX8o9sRICLOJ6cvHU7WNX8iIn42pw/oqVgEWDsifh0RD5HD85cneyf9hFxg+aOS3ltjjD2lkuS3JNcr2I0sQLyPrP76OLnI+D3ADk7yqZLkV4+cY/8K4HpJ85NrFkwkF9FZNXI9Zif5GdD428bSePhOYM2I+Jqkl8hRhx+NiK9ExOtmUJxTqxzaRcQfJG0t6Z6IWIFcqm0w8HLp9/1zcv6f+2sNtAdIWpOcTniH8v0ZCtwVEU+SCetTwM+B90bE5TWG2lMkrVDaxgT8L3C0pO0iYp8yzmAi2eX5NPIu6Jkaw51tNbZE3yqVS1qf7Jp1sqT9S1fJnwFrSTq4zhhnBxFxJXCgpKfJXjZjSz/mVk+HSyJiYr1R9oR7yXmQxpXv3t3AUEmrSponcvWsi5kDCledkjQc+LmkE8vF8UFyvYe5ASLiAOD35PiMIRHxhXJnaTOocV+6Vh1pKclvQs5dczD5ZdmvDK74kqS5yWH6y7pL27RFLq+3PfC9mDq0fDDwUuT88nMs5ZTVr5Quk7uSc6BfHBG7SLqTHJtxa7mT3I4cUzDHk7Qt2d7zEeAsSS+QPWz+Q2XiwIjYX9I/yLEGf6sj1iZoVGOspMXJYfeXlz64+wALR8SZZeDOOuRyYqdGxLclLea6vs4pJ5b6HrBqqZKYo0namhxwdx9wd+TskwuQ4zNejog9Je0ErE1pkI2Iu+qKt1eUJH8KuSznOEnLAleS0w3PTVYFPknOjzQ5Ir5YW7AN0bREvxk5WvMf5OLJ7yUH87ytlPDnBs4jFw051b1FZlxJbs9GxG/qjqVO5aJ3LNmYfz85w+n+pf/3EHLen5cjYs9y/pDowsLxva6MJ/gh8MmIuFE5/fczpR3tXDLZf5GcI2lh4KqIuK+2gBuiEVU3pSS/eURcqJzB7izgpoj4ZhnFeU0ZYbcGOdR8PLnwss2giJgAc/bkbpIWASaQDauXSVqPHF39RUmDIuIASXsBP5L0/YjYA3i5zph7yAvAS8DzkuYFjlCuSPZP4Any7metiDi7vhCbZ7Yv0SvXgtyWbHD9fUR8XdIHgPWBG8i5vj9PzluzBPB+snrnHeS6qnPcJFs26yRtQ/ay2ZucDuKPwDeBccC9EbFr6Ro4LCL+XlugPaY0VB9KzsO/Bjl75x/ICd62JxP+WLIL9GNzamGiv832JfqSqMdLGgFsIulfkXNTPw9sTN4+f7zcTs9LdtU6jCyNOcnbTImcsO0VchbKoyPiVPjvWsOXSRoeEY/j7oCvUapQv05eGJcBLouIFwAkHUAm/tOd4PvXbJ/o4b+LBe9eNj9U6v3OlxTANpLmI3vfDCVL+jtHxJ01hWsNERFXloFR50j6WkT8ixwkNZTs8219iIinybVyr2vtUy4msgZ5N+Qk38+aUHWzKNkvfl+yL/NYcmj5ryLiotLl7fbWCEQ3ill/KwWNL5CTlu1KLlT9l3qjmj1IWpIcNbwfOR2E37cB0IQSfatK5pUyWvNKsg7+MEnzlWkOqv3rneStX0XEz0v33R+TPbw8rUHn/kWZRyk8keCAme1K9K2EXfrePhoRz0s6BFgR+GJE3Fv6Lm8NnOESgnVLKVh4rVLrObNVib6S5LcjW+5vk/QscC05++Slkn4AHAjs6yRv3eQkb71qdizRr002rG4JfJqcTXEXcnKtLclZKG8PL0pgZgbMBiV6SauQCXyuMojieeBy4G1kV8k9y8i6tSPi0hpDNTPrST09e6VydaMfkPOEjJF0Pdl4806yh8OOETG59Ho4scyGZ2ZmFT1bdVO6XU0Avh8Rp5d9V5MjXecDViGXGptEjkw8rkxBbGZmFb1cdbMw8ADwb0krla5Xk8j5qieSVTd7kwn/mCgrQ3mwhZnZa/Vkib7Su2Ydci7568hl7bYGdoqIhyvnDoqIV5zkzcz61nOJvpLkVydL9KsCh5BzyX84In5fJkaS56oxM5u+nmuMLUl+LDkT4KiIuJmcffJmYJSkVcoIVyd5M7MO9GKJfm3gO2QVzd/KrJSQ0xycAfwJOCcinqspRDOz2UovNsYuRC4SvEaZkOydwArAbsBngVed5M3MOld7ib5SJ7808AgwHNgD2BM4jWyI3Y6c1+bi+iI1M5s91Z7o4b+LBR8C3Ao8S9bJv1QmLFufnPLgwxHxuxrDNDObLdXeGCtpTeAzZCl+fmDdcmiuUl9/PnCkk7yZ2czpeh19H/3d5wEuIVeXeSuwe0T8p1wAHgZ2iIi73U/ezGzmdLVEX1Z936s8XkfSR8mRrjsAXyWT+j2StgaOI6tv7obsdtnNWM3MmqKrJfpS5/4mSf8G7ifXbv27pHHASHJ91/uAz5Fz1zzZzfjMzJqoa42xld41C5I9aYZHxJLl2MrA6sAHgCeAyyPiclfXmJnNuq4k+kqSHwE8Tk5Y9hFgf2C9iHhE0lIRMaVyrpO8mVk/6ErVTUnc2wAHATcB/4iIU8r88TdIOgg4TtJurpM3M+tf3SrRr0NOa7A92ZVyYXKKgxckHQWsRc47f8WAB2NmNocZ0BJ9pfplCbJXzdLk/PG7liS/UkScKmm+iHjW1TVmZv1vQEr07XPElymHf0iuDPWuiHi0VOXsCBwcEf/p9yDMzAzo5xJ9qXN/ISKelrQJsIGkvwJ3kUsALgqMLt0rTwGOd5I3MxtY/VailzQUOAYQ8DtySuHvAxsCfyR72zwJ7EsOkro0Isa7usbMbGD1Z6IXsBWwEdm4ekFE/LD0kd8RmCsiPidpnvK8zzvJm5kNvH6ZAqGSsK8CriZL9XtJGla6S14OvFfSMhHxQkQ8D+5CaWbWDbOc6CsNrkuQpfZfkVU49wKflDQf8DyZ/M3MrMtmqeqmkuS3Bk4ArgVejIgjyzzyx5BTG9xHLv932ayHbGZmM2KmEr2keVvVL5I2As4B3geMBQ4FroiIvSWNBvYBvhkRt7hO3sys+2a46kbSm4BTJS1Udg0h13NdhpxueENglKRvR8RE4JiIuAVcJ29mVocZLtFLWoRcCWoQMCIibizzzJ8HXBIRP5P0ebJ0v1NE3N7fQZuZWec6LtFLap37r4h4EHgv8HlJ65dqnGeBpSVtD4wCtnWSNzOrX0clekmrkHPFDyN7z3wOeAT4MLAlcAQ56nVfci6bMyNi3ADFbGZmM2C6JXpJqwI/Jke2Ti67J5Lru34d+A1wKvBEROwDbBUR48oAKjMzq9k057qRNIqcxuDoiBhf2f8wMB54OznVwSDgdEm7A0+BG17NzHrFNKtuJL0L+F1EzFW2h0bEc+XxGcBiZJXOosDQiLh/4EM2M7MZMc2qm4j4A7lg998kDY+I50oPG4AbyAvFqxHxqJO8mVlvmm4dfUT8HDgQ+JOkRVoDpYAXgH9JGlLpkWNmZj2mowRdSfYT4b8NtKcCl0fEixHx6sCFaGZms2KGBkxJGgP8iJyw7IiImDBQgZmZWf+YmZGxmwILRcRPBiYkMzPrTzM9e6UnKDMzmz0MyOLgZmbWO9xbxsys4ZzozcwazonezKzhnOjNzBrOid7MrOGc6M3MGu7/AQlSxFRN6cd5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVsqeh6yMFgU"
      },
      "source": [
        "## **Ensemble Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkPw0yt5MHuP",
        "outputId": "f042efbc-9721-4b16-c903-bd813c14a4fb"
      },
      "source": [
        "# Install and Import Dependencies\n",
        "!pip install vecstack\n",
        "from vecstack import stacking"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vecstack\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/a1/b9a1e9e9e5a12078da1ab9788c7885e4c745358f7e57d5f94d9db6a4e898/vecstack-0.4.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.0.1)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vecstack: filename=vecstack-0.4.0-cp37-none-any.whl size=19877 sha256=4ad57545cffe0bf464e4258de259c29d17495b738fdb6124e6dd398d80ffb253\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/bb/4e/f6488433d53bc0684673d6845e5bf11a25240577c8151c140e\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rEKwYhDMKri",
        "outputId": "e8fbf9f5-6b50-47c2-9687-d10b2bd93ba8"
      },
      "source": [
        "# get all models, 1-st level.\n",
        "models = [v[0] for v in result] # tanpa neural network\n",
        "print('Number of model:',len(models))\n",
        "\n",
        "t0 = time()\n",
        "\n",
        "# Compute stacking features\n",
        "S_train, S_test = stacking(models, x_train, y_train, x_test, n_folds = 3, metric=accuracy_score,\n",
        "                           shuffle = True, random_state = 7, verbose = 1)\n",
        "\n",
        "# Initialize 2-nd level model\n",
        "model = models[-1]\n",
        "\n",
        "# Fit 2-nd level model\n",
        "model = model.fit(S_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_test_pred = model.predict(S_test)\n",
        "\n",
        "train_test_time = time() - t0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of model: 13\n",
            "task:         [regression]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [13]\n",
            "\n",
            "model  0:     [LogisticRegression]\n",
            "    ----\n",
            "    MEAN:     [0.76909722] + [0.02009694]\n",
            "    FULL:     [0.76909722]\n",
            "\n",
            "model  1:     [SVC]\n",
            "    ----\n",
            "    MEAN:     [0.75347222] + [0.02009694]\n",
            "    FULL:     [0.75347222]\n",
            "\n",
            "model  2:     [GradientBoostingClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.74652778] + [0.01299187]\n",
            "    FULL:     [0.74652778]\n",
            "\n",
            "model  3:     [ExtraTreesClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.73437500] + [0.02586747]\n",
            "    FULL:     [0.73437500]\n",
            "\n",
            "model  4:     [BaggingClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.73958333] + [0.01948780]\n",
            "    FULL:     [0.73958333]\n",
            "\n",
            "model  5:     [AdaBoostClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.72743056] + [0.02734031]\n",
            "    FULL:     [0.72743056]\n",
            "\n",
            "model  6:     [GaussianNB]\n",
            "    ----\n",
            "    MEAN:     [0.75520833] + [0.02655739]\n",
            "    FULL:     [0.75520833]\n",
            "\n",
            "model  7:     [MLPClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.74479167] + [0.03897560]\n",
            "    FULL:     [0.74479167]\n",
            "\n",
            "model  8:     [XGBClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.74826389] + [0.01718662]\n",
            "    FULL:     [0.74826389]\n",
            "\n",
            "model  9:     [LGBMClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.74479167] + [0.01533292]\n",
            "    FULL:     [0.74479167]\n",
            "\n",
            "model 10:     [KNeighborsClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.70486111] + [0.02182258]\n",
            "    FULL:     [0.70486111]\n",
            "\n",
            "model 11:     [DecisionTreeClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.68576389] + [0.03835195]\n",
            "    FULL:     [0.68576389]\n",
            "\n",
            "model 12:     [RandomForestClassifier]\n",
            "    ----\n",
            "    MEAN:     [0.75520833] + [0.01533292]\n",
            "    FULL:     [0.75520833]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai9B-vQzMUyr",
        "outputId": "50f38a09-7164-422a-b3b2-4ce3f0bd1964"
      },
      "source": [
        "## Print vecstack result\n",
        "accuracy = accuracy_score(y_test, y_test_pred)*100\n",
        "print(\"Stacking accuracy : {0:.2f}%\".format(accuracy))\n",
        "print(\"train and test time: {0:.2f}s\".format(train_test_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stacking accuracy : 79.69%\n",
            "train and test time: 3.76s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}